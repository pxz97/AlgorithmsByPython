# 文本相似度/匹配模型归纳总结
在自然语言处理（Natural Language Processing，NLP）领域中，经常会涉及到如何度量两个文本间相似度的问题。
例如在对话系统（Dialog system）和信息检索（Information retrieval）等任务中，文本相似度的匹配尤为重要。
比如，基于聚类算法发现微博热点话题时，我们需要度量每个文本之间的相似度，然后将内容足够相似的微博内容聚成
一个簇；在问答系统中，我们会准备一些经典问题的对应答案，当用户的问题与经典问题很相似时，系统会直接返回准备
好的答案；在对语料库进行预处理时，我们需要基于文本的相似度，把重复的文本给挑出来并删掉。

总之，文本相似度算法一直是自然语言处理领域中非常重要的一个分支，
在此部分中，我将会对文本相似度/匹配方法进行总结，由于本人实力有限，如有错误，恳请大家指正！

综合现有的文本相似度匹配方法，可以大致将其分为以下三类：

1. 基于关键词
2. 基于向量空间
3. 基于深度学习

### 1 基于关键词分类
#### 1.1 n-gram相似度
n-gram是一种基于统计语言模型的算法。它的思想是将文本里面的内容按照字词进行大小为n的滑动窗口操作，
每一个字词片段称为一个gram。这种切分方式非常简单：使用一个长度为n的窗口，从左到右、逐字符滑动；每一步都会框到一个
字符串，即一个gram。如表中所示，是几种常见的n-gram切分效果实例。

|取值|名称|切分实例|
|-----|-----|-----|
|1|unigram|文/本/相/似/度/匹/配|
|2|bigram|文本/本相/相似/似度/度匹/匹配|
|3|trigram|文本相/本相似/相似度/似度匹/度匹配|
n-gram相似度计算方法是指按长度n将原句划分为词段，然后对两个句子A和B，根据共有的词段数量去定义两个句子的相似度：

<p align="center">
    
</p>
    